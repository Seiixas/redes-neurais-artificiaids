{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear Multivariada (Adaline)\n",
    "\n",
    "## Adaline (Adaptive Linear Neuron)\n",
    "\n",
    "O Adaline é um modelo de neurônio oriundo da evolução do Perceptron (criado em 1957 por Frank Rosenblatt). Este modelo neural se diferencia por receber $N$ valores reais e retornar uma saída real.\n",
    "\n",
    "$$f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$$\n",
    "\n",
    "## Problema a ser resolvido\n",
    "\n",
    "O Titanic foi um navio que afundou na madrugada de 14 de abril de 1912 durante sua viagem inaugural. O neurônio Adaline irá analisar o arquivo `titanic.csv` que possui as seguintes informações:\n",
    "\n",
    "$$nome = x \\in \\{1, 2, 3\\}$$\n",
    "\n",
    "$$idade = x \\in \\mathbb{R} \\mid x \\ge 0$$\n",
    "\n",
    "$$sexo = x \\in \\{0,1\\}$$\n",
    "\n",
    "$$sobreviveu = x \\in \\{0,1\\}$$\n",
    "\n",
    "Baseados nos valores de $nome$, $idade$ e $sexo$, determinar se determinada pessoa com essas características sobreviveu ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Geradora de Dados - $G(x)$ ou $y$\n",
    "\n",
    "$$G(x) = ??$$\n",
    "\n",
    "### Explicação\n",
    "\n",
    "A função $G(x)$ representa o resultado eventos que já aconteceram na vida real ocasionados por determinados dados de entrada. Essa função ela é inacessível a nós, pois o evento já ocorreu e, para além disso, múltiplas variáveis são relacionadas ao evento ocorrido, variáveis essas que também são inacessíveis com total precisão.\n",
    "\n",
    "Por exemplo: O Titanic, o maior navio de sua época, afundou no dia 15 de abril de 1912. Diversas variáveis determinaram naquela madrugada quem sobreviveu ao evento ou quem não sobreviveu. Acontece que o resultado desse evento ($G(x)$) está no passado e apenas quem esteve presente sabe o que ocorreu.\n",
    "\n",
    "### Parâmetros\n",
    "\n",
    "$$x \\in \\{0, 1\\}^n $$\n",
    "\n",
    "$$y \\in \\{0, 1\\}$$\n",
    "\n",
    "Onde $x$ representam as variáveis do acontecimento e $y$ (ou $G(x)$) o seu resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for row in df.iterrows():\n",
    "  data = row[1]\n",
    "\n",
    "  group = data.get(\"Nome\")\n",
    "  age = data.get(\"Idade\")\n",
    "  gender = data.get(\"Sexo\")\n",
    "  survived = data.get(\"Sobreviveu\")\n",
    "  \n",
    "  if (np.isnan(age) or np.isnan(group) or np.isnan(gender) or np.isnan(survived)):\n",
    "    continue\n",
    "\n",
    "  x.append([group, age, gender])\n",
    "  y.append(int(survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entradas, pesos, viés, taxa de aprendizado - $n$, $w$, $b$ e $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantidade de entradas ($n$)\n",
    "\n",
    "$$n = |x| $$\n",
    "\n",
    "\n",
    "A quantidade de entradas é a quantidade de valores $x$ que resultam em um $y$. Nesse caso, para três valores de $x$, um valor de $y$ foi gerado. Logo, o valor de $n$ é a cardinalidade (ou tamanho) do conjunto de $x$ (nesse caso, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos ($w$)\n",
    "\n",
    "$$w = \\begin{bmatrix}\n",
    "a_{1} & ... & a_{n}\n",
    "\\end{bmatrix} \\in \\mathbb{R}$$\n",
    "\n",
    "Em um neurônio Adaline, o peso determina a influência de cada entrada e saída do neurônio. De início, o peso é inicializado com valores aleatórios e esse valor é ajustável pela função de aprendizado a medida que o neurônio erra ao tentar reproduzir um valor de  $\\hat{y}$ que é diferente de $y$. Como esse é um problema de regressão multivariável, cada peso $w_{i}$ é associado a um valor $x_{i}$ e $w_{i}$ é compartilhável dentre todos os valores $x_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viés ($b$)\n",
    "\n",
    "$$b = x \\in \\mathbb{R}$$\n",
    "\n",
    "O termo de bias é um valor que atua como um compensador e que é aplicado ao final do cálculo da função de inferência. Esse termo independe de qualquer valor $x_{ij}$ e $w_{i}$ e, assim como os pesos, o $b$ é inicializado com um valor aleatório e ajustado na função de aprendizado a medida que o neurônio erra a saída $\\hat{y}$ em comparação com $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de aprendizado ($\\alpha$)\n",
    "\n",
    "$$\\alpha = x \\in \\mathbb{R}$$\n",
    "\n",
    "A taxa de aprendizado é uma constante real que define o tamanho dos ajustes feitos pela função de aprendizado. Valores maiores representam mudanças mais bruscas na atualização dos pesos ${w_{i}}$ e ${b}$, assim como valores menores representam atualizações mais sutis nos mesmos termos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.0021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de inferência - $\\hat{y}$ ou $f(x)$\n",
    "\n",
    "$$\\hat{y} = \\sum_{i=1}^{n} w_{i} \\cdot x_{i} + b$$\n",
    "\n",
    "<div align=\"center\">\n",
    "  ou\n",
    "</div>\n",
    "\n",
    "$$\\hat{y} = w_{1} \\cdot x_{1} + ... + w_{n} \\cdot x_{n} + b$$\n",
    "\n",
    "\n",
    "A função de inferência tenta replicar a função $G(x)$ e reproduzir um valor de $\\hat{y}$ baseado em um modelo. Essa tentativa é baseada no somatório da multiplicação entre os pesos $w_{i}$ e os dados $x_{i}$ somado ao termo $b$.\n",
    "\n",
    "Os parâmetros dessa função ($w$ e $b$) são chamados de modelo $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x: list, weights: list, bias: float):\n",
    "  return np.dot(x, weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de aprendizado - $F(x)$\n",
    "\n",
    "$$\\varepsilon = y - \\hat{y}$$\n",
    "\n",
    "$$F(x) = \\begin{cases}\n",
    "      w_i^{t+1} &= w_i + \\alpha \\cdot \\varepsilon \\cdot x_{i} \\\\\n",
    "      b^{t+1} &= b + \\alpha \\cdot \\varepsilon\n",
    "   \\end{cases}$$\n",
    "\n",
    "A função de aprendizado atualiza os valores do modelo $\\theta$ (${w}$ e ${b}$) baseado nos valores de $\\alpha$, $\\varepsilon$ e $x_{i}$ (no caso de $b$, apenas $\\alpha$ e $\\varepsilon$). Lembrando que a taxa de erro $\\varepsilon$ é calculado pela diferença entre $y$ e $\\hat{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(x: list, y: float, y_hat: float, weights: list, alpha: float, bias: float):\n",
    "  error = y - y_hat\n",
    "  \n",
    "  for i in range(n):\n",
    "    weights[i] = weights[i] + alpha * error * x[i]\n",
    "  bias = bias + alpha * error\n",
    "\n",
    "  return weights, bias, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função degrau - $d(y)$\n",
    "\n",
    "$$d: \\{\\mathbb{R}\\} \\rightarrow \\{0,1\\}$$\n",
    "\n",
    "$$\n",
    "d(y) = \\begin{cases}\n",
    "      1 & \\text{se } y \\ge 0 \\\\\n",
    "      0 & \\text{se } y \\lt 1\n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "A função de inferência ($f(x)$) retorna um valor real. Porém, para definir se uma pessoa sobreviveu (`True`) ou não (`False`), é necessário adicionar uma função degrau (ou de ativação) para ressignificar o valor de $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(y: float) -> (int):\n",
    "  return 0 if y < 1 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "As épocas definem a quantidade de vezes em que o modelo será treinado. Definimos um número de épocas tal que:\n",
    "\n",
    "$$epoch = x \\in \\mathbb{N}$$\n",
    "\n",
    "Nesse caso, vamos definir 5.000 épocas.\n",
    "\n",
    "Para cada época, vamos tentar um valor $\\hat{y}$ por meio da função de inferência $f(x)$. Em seguida, enviamos esse valor $\\hat{y}$ juntamente com o valor esperado $y$ e o modelo $\\theta$ ($w$ e $b$) para a função de aprendizagem $F(x)$.\n",
    "\n",
    "A função de aprendizagem utiliza a taxa de erro $\\varepsilon = \\hat{y} - y$ para atualizar o modelo $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5000\n",
    "errors = np.zeros(EPOCH)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "  for i in range(len(x)):\n",
    "    random_coordinates = np.random.randint(0, n)\n",
    "\n",
    "    y_hat = inference(x[random_coordinates], w, b)\n",
    "    w, b, error = learn(x[random_coordinates], y[random_coordinates], y_hat, w, a, b)\n",
    "    errors[epoch] += error\n",
    "    last_error = error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados do Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico\n",
    "\n",
    "O gráfico abaixo representa uma relação entre a taxa de erros em cada época."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([epoch for epoch in range(EPOCH)], errors)\n",
    "plt.xlabel('Erros')\n",
    "plt.ylabel('Época')\n",
    "plt.title('Relação entre erros e acertos de cada época')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório\n",
    "\n",
    "O relatório abaixo mostra os valores do modelo $\\theta$ ($w$ e $b$), juntamente com a última taxa de erros $\\varepsilon$ registrada. Além disso, todos os valores de $x$ são usados na função de indução $f(x)$ com o modelo $\\theta$, dessa forma obtendo os valores para $\\hat{y}$.\n",
    "\n",
    "Em seguida, cada valor de $\\hat{y}_{i}$ é comparado com o respectivo valor ${y}_{i}$ para verificar o quão assertivo o treinamento foi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = [step(inference(x[i], w, b)) for i in range(len(x))]\n",
    "correct = sum(1 for i in range(len(x)) if y[i] == y_hat[i])\n",
    "\n",
    "print(\"Results\")\n",
    "print(f\"\\nTheta\\nWeights   = {w}\\nBias      = {b}\\nError     = {last_error}\")\n",
    "print(f\"\\nCorrect   = {correct}\\nIncorrect = {len(x) - correct}\\nTotal     = {len(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o Modelo\n",
    "\n",
    "O trecho de código abaixo testa o modelo treinado acima. Dessa forma, o usuário pode preencher os dados de idade, gênero e classe da seguinte maneira:\n",
    "\n",
    "Classe = {1,2,3} : A classe do passageiro\n",
    "\n",
    "Idade = [0, 100]: A idade do passageiros\n",
    "\n",
    "Sexo = {0,1}: O sexo do passageiro, onde 0 = Masculino e 1 = Feminino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você sobreviveu\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  age = float(input(\"Digite sua idade: \"))\n",
    "  gender = int(input(\"Digite o seu gênero (0 ou 1): \"))\n",
    "  group = int(input(\"Digite o seu grupo (1, 2 ou 3): \"))\n",
    "\n",
    "  survived = step(inference([group, age, gender], w, b))\n",
    "\n",
    "  print(f\"Você {'sobreviveu' if survived else 'não sobreviveu'}\")\n",
    "except ValueError:\n",
    "  print(\"O valor é inválido\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
